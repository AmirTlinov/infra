#!/usr/bin/env python3
from __future__ import annotations

import argparse
import difflib
import json
import os
import re
import selectors
import subprocess
import sys
import tempfile
import time
from dataclasses import dataclass
from pathlib import Path
from typing import Any


def _repo_root() -> Path:
    return Path(__file__).resolve().parents[1]


def _default_ts_root() -> Path | None:
    candidates = [
        os.environ.get("INFRA_TS_PATH"),
    ]
    for raw in candidates:
        if not raw:
            continue
        path = Path(raw).expanduser()
        if path.exists():
            return path
    return None


def _normalize_env(env: dict[str, str], *, unsafe_local: bool, tool_tier: str) -> dict[str, str]:
    out = dict(env)
    out["INFRA_TOOL_TIER"] = tool_tier
    if unsafe_local:
        out["INFRA_UNSAFE_LOCAL"] = "1"
    else:
        out.pop("INFRA_UNSAFE_LOCAL", None)
    return out


def _json_dumps(obj: Any) -> str:
    return json.dumps(obj, ensure_ascii=False, sort_keys=True, separators=(",", ":"))


def _write_json(path: Path, value: Any) -> None:
    path.write_text(json.dumps(value, ensure_ascii=False, indent=2) + "\n", encoding="utf-8")


def _build_fixtures(root: Path) -> tuple[Path, Path]:
    root.mkdir(parents=True, exist_ok=True)

    # Keep keys sorted in JSON so TS (Map insertion order) and Rust (sorted output) align.
    runbooks = {
        "a.echo": {
            "description": "Echo (fixture)",
            "when": {},
            "steps": [{"tool": "help", "args": {"query": "ssh"}}],
        },
        "b.context": {
            "description": "Context list (fixture)",
            "when": {},
            "steps": [{"tool": "mcp_context", "args": {"action": "list"}}],
        },
    }
    capabilities = {
        "version": 1,
        "capabilities": {
            "a.echo": {
                "intent": "a.echo",
                "description": "Echo intent (fixture)",
                "runbook": "a.echo",
                "tags": ["fixture"],
                "inputs": {"required": [], "defaults": {}, "map": {}},
                "when": {},
                "effects": {"kind": "read", "requires_apply": False},
            },
            "b.context": {
                "intent": "b.context",
                "description": "Context intent (fixture)",
                "runbook": "b.context",
                "tags": ["fixture"],
                "inputs": {"required": [], "defaults": {}, "map": {}},
                "when": {},
                "effects": {"kind": "read", "requires_apply": False},
            },
        },
    }

    runbooks_path = root / "runbooks.json"
    capabilities_path = root / "capabilities.json"
    _write_json(runbooks_path, runbooks)
    _write_json(capabilities_path, capabilities)
    return runbooks_path, capabilities_path


def _prepare_repo_fixture(root: Path) -> None:
    # Deterministic context markers for both servers.
    (root / ".git").mkdir(parents=True, exist_ok=True)
    (root / ".github" / "workflows").mkdir(parents=True, exist_ok=True)
    (root / "package.json").write_text("{}", encoding="utf-8")
    (root / "Cargo.toml").write_text("[package]\nname = \"fixture\"\nversion = \"0.0.0\"\n", encoding="utf-8")


def _canonicalize_tools(result: dict[str, Any]) -> list[dict[str, Any]]:
    tools = result.get("tools")
    if not isinstance(tools, list):
        raise ValueError("result.tools must be a list")
    out: list[dict[str, Any]] = []
    for item in tools:
        if not isinstance(item, dict):
            raise ValueError("tool entry must be an object")
        out.append(item)
    out.sort(key=lambda t: str(t.get("name", "")))
    return out


def _tool_name_set(tools: list[dict[str, Any]]) -> set[str]:
    names: set[str] = set()
    for tool in tools:
        name = tool.get("name")
        if isinstance(name, str):
            names.add(name)
    return names


@dataclass
class Spawned:
    name: str
    proc: subprocess.Popen[str]
    selector: selectors.BaseSelector
    stderr_tail: list[str]

    def terminate(self) -> None:
        if self.proc.poll() is not None:
            return
        try:
            self.proc.terminate()
            self.proc.wait(timeout=2.0)
        except Exception:
            try:
                self.proc.kill()
            except Exception:
                pass

    def _drain_stderr(self) -> None:
        if self.proc.stderr is None:
            return
        try:
            for _ in range(200):
                events = self.selector.select(timeout=0)
                if not events:
                    break
                for key, _ in events:
                    if key.fileobj is not self.proc.stderr:
                        continue
                    line = self.proc.stderr.readline()
                    if not line:
                        continue
                    self.stderr_tail.append(line.rstrip("\n"))
                    if len(self.stderr_tail) > 60:
                        self.stderr_tail[:] = self.stderr_tail[-60:]
        except Exception:
            return

    def send(self, payload: dict[str, Any]) -> None:
        if self.proc.stdin is None:
            raise RuntimeError(f"{self.name}: stdin is closed")
        wire = _json_dumps(payload) + "\n"
        self.proc.stdin.write(wire)
        self.proc.stdin.flush()

    def recv(self, *, timeout_s: float) -> dict[str, Any]:
        if self.proc.stdout is None:
            raise RuntimeError(f"{self.name}: stdout is closed")
        deadline = time.time() + timeout_s
        while time.time() < deadline:
            if self.proc.poll() is not None:
                self._drain_stderr()
                tail = "\n".join(self.stderr_tail[-20:])
                raise RuntimeError(f"{self.name}: process exited early (rc={self.proc.returncode})\n{tail}")

            events = self.selector.select(timeout=0.05)
            for key, _ in events:
                if key.fileobj is self.proc.stdout:
                    raw = self.proc.stdout.readline()
                    if not raw:
                        continue
                    line = raw.strip()
                    if not line:
                        continue
                    try:
                        data = json.loads(line)
                    except Exception as exc:
                        self._drain_stderr()
                        tail = "\n".join(self.stderr_tail[-20:])
                        raise RuntimeError(
                            f"{self.name}: non-JSON stdout line: {line!r}\n{tail}"
                        ) from exc
                    if not isinstance(data, dict):
                        raise RuntimeError(f"{self.name}: expected JSON object, got: {type(data)}")
                    return data

                if self.proc.stderr is not None and key.fileobj is self.proc.stderr:
                    raw = self.proc.stderr.readline()
                    if not raw:
                        continue
                    self.stderr_tail.append(raw.rstrip("\n"))
                    if len(self.stderr_tail) > 60:
                        self.stderr_tail[:] = self.stderr_tail[-60:]

        self._drain_stderr()
        tail = "\n".join(self.stderr_tail[-20:])
        raise TimeoutError(f"{self.name}: timeout waiting for response\n{tail}")

    def expect_no_response(self, *, quiet_for_s: float) -> None:
        if self.proc.stdout is None:
            return
        deadline = time.time() + quiet_for_s
        while time.time() < deadline:
            if self.proc.poll() is not None:
                self._drain_stderr()
                tail = "\n".join(self.stderr_tail[-20:])
                raise RuntimeError(
                    f"{self.name}: process exited while expecting silence (rc={self.proc.returncode})\n{tail}"
                )
            events = self.selector.select(timeout=0.05)
            for key, _ in events:
                if key.fileobj is self.proc.stdout:
                    raw = self.proc.stdout.readline()
                    if raw.strip():
                        self._drain_stderr()
                        tail = "\n".join(self.stderr_tail[-20:])
                        raise RuntimeError(
                            f"{self.name}: expected no response, but got stdout: {raw.strip()!r}\n{tail}"
                        )
                if self.proc.stderr is not None and key.fileobj is self.proc.stderr:
                    raw = self.proc.stderr.readline()
                    if raw:
                        self.stderr_tail.append(raw.rstrip("\n"))
                        if len(self.stderr_tail) > 60:
                            self.stderr_tail[:] = self.stderr_tail[-60:]


def _spawn(name: str, *, cmd: list[str], cwd: Path, env: dict[str, str]) -> Spawned:
    proc = subprocess.Popen(
        cmd,
        cwd=str(cwd),
        env=env,
        stdin=subprocess.PIPE,
        stdout=subprocess.PIPE,
        stderr=subprocess.PIPE,
        text=True,
        bufsize=1,
    )
    sel = selectors.DefaultSelector()
    assert proc.stdout is not None
    sel.register(proc.stdout, selectors.EVENT_READ)
    if proc.stderr is not None:
        sel.register(proc.stderr, selectors.EVENT_READ)
    return Spawned(name=name, proc=proc, selector=sel, stderr_tail=[])


def _handshake(client: Spawned) -> None:
    client.send(
        {
            "jsonrpc": "2.0",
            "id": 1,
            "method": "initialize",
            "params": {
                "protocolVersion": "2025-06-18",
                "capabilities": {},
                "clientInfo": {"name": "sf-parity", "version": "0"},
            },
        }
    )
    response = client.recv(timeout_s=5.0)
    if response.get("id") != 1:
        raise RuntimeError(f"{client.name}: initialize: unexpected id: {response.get('id')!r}")
    if "error" in response and response["error"] is not None:
        raise RuntimeError(f"{client.name}: initialize error: {response['error']!r}")
    result = response.get("result")
    if not isinstance(result, dict) or result.get("protocolVersion") != "2025-06-18":
        raise RuntimeError(f"{client.name}: initialize: bad result: {result!r}")

    client.send({"jsonrpc": "2.0", "method": "notifications/initialized", "params": {}})
    client.expect_no_response(quiet_for_s=0.25)


def _tools_list(client: Spawned) -> list[dict[str, Any]]:
    client.send({"jsonrpc": "2.0", "id": 2, "method": "tools/list", "params": {}})
    response = client.recv(timeout_s=10.0)
    if response.get("id") != 2:
        raise RuntimeError(f"{client.name}: tools/list: unexpected id: {response.get('id')!r}")
    if "error" in response and response["error"] is not None:
        raise RuntimeError(f"{client.name}: tools/list error: {response['error']!r}")
    result = response.get("result")
    if not isinstance(result, dict):
        raise RuntimeError(f"{client.name}: tools/list: result must be object")
    return _canonicalize_tools(result)


def _tools_call_envelope(
    client: Spawned, *, call_id: int, name: str, arguments: dict[str, Any]
) -> dict[str, Any]:
    client.send(
        {
            "jsonrpc": "2.0",
            "id": call_id,
            "method": "tools/call",
            "params": {"name": name, "arguments": arguments},
        }
    )
    response = client.recv(timeout_s=15.0)
    if response.get("id") != call_id:
        raise RuntimeError(
            f"{client.name}: tools/call({name}): unexpected id: {response.get('id')!r}"
        )
    if "error" in response and response["error"] is not None:
        raise RuntimeError(f"{client.name}: tools/call({name}) error: {response['error']!r}")
    result = response.get("result")
    if not isinstance(result, dict):
        raise RuntimeError(f"{client.name}: tools/call({name}): result must be object")
    content = result.get("content")
    if not isinstance(content, list) or not content:
        raise RuntimeError(f"{client.name}: tools/call({name}): missing content array")

    text: str | None = None
    for item in content:
        if not isinstance(item, dict):
            continue
        if item.get("type") == "text" and isinstance(item.get("text"), str):
            text = item["text"]
            break
    if text is None:
        raise RuntimeError(f"{client.name}: tools/call({name}): no text content")

    try:
        env = json.loads(text)
    except Exception as exc:
        raise RuntimeError(f"{client.name}: tools/call({name}): invalid JSON envelope") from exc
    if not isinstance(env, dict):
        raise RuntimeError(
            f"{client.name}: tools/call({name}): envelope must be object, got {type(env)}"
        )
    return env


def _replace_prefixes(value: Any, prefixes: list[tuple[str, str]]) -> Any:
    if isinstance(value, str):
        for raw, token in prefixes:
            if raw and value.startswith(raw):
                return token + value[len(raw) :]
        return value
    if isinstance(value, list):
        return [_replace_prefixes(v, prefixes) for v in value]
    if isinstance(value, dict):
        return {k: _replace_prefixes(v, prefixes) for k, v in value.items()}
    return value


def _canonicalize_envelope(env: dict[str, Any], *, prefixes: list[tuple[str, str]] | None = None) -> dict[str, Any]:
    out = json.loads(json.dumps(env))
    if isinstance(out, dict):
        if "duration_ms" in out:
            out["duration_ms"] = 0
        if "summary" in out and isinstance(out.get("summary"), str):
            out["summary"] = re.sub(r"\b\d+ms\b", "0ms", out["summary"])
    if prefixes:
        out = _replace_prefixes(out, prefixes)
    return out


def _diff_envelope(rust: dict[str, Any], ts: dict[str, Any], *, name: str) -> str | None:
    a = _json_dumps(ts).splitlines(keepends=True)
    b = _json_dumps(rust).splitlines(keepends=True)
    if a == b:
        return None
    diff = difflib.unified_diff(
        a,
        b,
        fromfile=f"ts:tools/call:{name}",
        tofile=f"rust:tools/call:{name}",
        n=2,
    )
    return "tool call envelope mismatch:\n" + "".join(diff)


def _diff_tools(rust: list[dict[str, Any]], ts: list[dict[str, Any]]) -> str | None:
    rust_names = _tool_name_set(rust)
    ts_names = _tool_name_set(ts)

    missing = sorted(ts_names - rust_names)
    extra = sorted(rust_names - ts_names)
    if missing or extra:
        lines = ["tool name set mismatch:"]
        if missing:
            lines.append(f"- missing in rust: {', '.join(missing)}")
        if extra:
            lines.append(f"- extra in rust: {', '.join(extra)}")
        return "\n".join(lines)

    rust_map = {t["name"]: t for t in rust if isinstance(t.get("name"), str)}
    ts_map = {t["name"]: t for t in ts if isinstance(t.get("name"), str)}
    for name in sorted(rust_map.keys()):
        a = _json_dumps(rust_map[name]).splitlines(keepends=True)
        b = _json_dumps(ts_map[name]).splitlines(keepends=True)
        if a != b:
            diff = difflib.unified_diff(
                b,
                a,
                fromfile=f"ts:{name}",
                tofile=f"rust:{name}",
                n=2,
            )
            return "tool definition mismatch:\n" + "".join(diff)
    return None


def _run_case(*, unsafe_local: bool, tool_tier: str, suite: str, ts_root: Path) -> None:
    root = _repo_root()
    rust_bin = root / "target" / "debug" / "sentryfrogg"
    if sys.platform == "win32":
        rust_bin = rust_bin.with_suffix(".exe")

    ts_entry = ts_root / "dist" / "sentryfrogg_server.js"
    if not ts_entry.exists():
        raise FileNotFoundError(f"ts entrypoint not found: {ts_entry}")

    env = os.environ.copy()
    env_rust = _normalize_env(env, unsafe_local=unsafe_local, tool_tier=tool_tier)
    env_ts = _normalize_env(env, unsafe_local=unsafe_local, tool_tier=tool_tier)

    with tempfile.TemporaryDirectory(prefix="sf-parity-rust-") as rust_state, tempfile.TemporaryDirectory(
        prefix="sf-parity-ts-"
    ) as ts_state, tempfile.TemporaryDirectory(
        prefix="sf-parity-context-rust-"
    ) as rust_context, tempfile.TemporaryDirectory(prefix="sf-parity-context-ts-") as ts_context:
        with tempfile.TemporaryDirectory(prefix="sf-parity-fixtures-") as fixtures_dir_raw:
            fixtures_dir = Path(fixtures_dir_raw)
            runbooks_path, capabilities_path = _build_fixtures(fixtures_dir)
            _prepare_repo_fixture(fixtures_dir)

            env_rust["MCP_PROFILES_DIR"] = rust_state
            env_ts["MCP_PROFILES_DIR"] = ts_state
            env_rust.pop("SENTRYFROGG_CONTEXT_REPO_ROOT", None)
            env_ts.pop("SENTRYFROGG_CONTEXT_REPO_ROOT", None)
            env_rust["SF_CONTEXT_REPO_ROOT"] = rust_context
            env_ts["SF_CONTEXT_REPO_ROOT"] = ts_context
            env_rust["MCP_DEFAULT_RUNBOOKS_PATH"] = str(runbooks_path)
            env_ts["MCP_DEFAULT_RUNBOOKS_PATH"] = str(runbooks_path)
            env_rust["MCP_DEFAULT_CAPABILITIES_PATH"] = str(capabilities_path)
            env_ts["MCP_DEFAULT_CAPABILITIES_PATH"] = str(capabilities_path)

            rust = _spawn("rust", cmd=[str(rust_bin)], cwd=root, env=env_rust)
            ts = _spawn("ts", cmd=["node", str(ts_entry)], cwd=ts_root, env=env_ts)

            try:
                _handshake(rust)
                _handshake(ts)

                rust_tools = _tools_list(rust)
                ts_tools = _tools_list(ts)

                diff = _diff_tools(rust_tools, ts_tools)
                if diff:
                    raise AssertionError(diff)

                available = _tool_name_set(rust_tools)
                prefixes = [
                    (rust_state, "<MCP_PROFILES_DIR>"),
                    (ts_state, "<MCP_PROFILES_DIR>"),
                    (rust_context, "<SF_CONTEXT_REPO_ROOT>"),
                    (ts_context, "<SF_CONTEXT_REPO_ROOT>"),
                ]

                base_args = {
                    "trace_id": f"sf-parity-{tool_tier}-{'unsafe' if unsafe_local else 'safe'}",
                    "response_mode": "ai",
                }

                def call_pair(
                    *, call_id: int, tool_name: str, arguments: dict[str, Any], label: str
                ) -> None:
                    if tool_name not in available:
                        return
                    rust_env = _canonicalize_envelope(
                        _tools_call_envelope(
                            rust,
                            call_id=call_id,
                            name=tool_name,
                            arguments=arguments,
                        ),
                        prefixes=prefixes,
                    )
                    ts_env = _canonicalize_envelope(
                        _tools_call_envelope(
                            ts,
                            call_id=call_id,
                            name=tool_name,
                            arguments=arguments,
                        ),
                        prefixes=prefixes,
                    )
                    diff = _diff_envelope(rust_env, ts_env, name=label)
                    if diff:
                        raise AssertionError(diff)

                call_pair(
                    call_id=10,
                    tool_name="help",
                    arguments={**base_args, "span_id": "help"},
                    label="help",
                )
                call_pair(
                    call_id=11,
                    tool_name="legend",
                    arguments={**base_args, "span_id": "legend"},
                    label="legend",
                )

                if suite in {"extended", "full"} and tool_tier == "full":
                    call_pair(
                        call_id=20,
                        tool_name="mcp_workspace",
                        arguments={
                            **base_args,
                            "span_id": "workspace_suggest",
                            "action": "suggest",
                            "limit": 5,
                            "include_untagged": True,
                            "cwd": str(fixtures_dir),
                            "repo_root": str(fixtures_dir),
                        },
                        label="mcp_workspace:suggest",
                    )

                    call_pair(
                        call_id=21,
                        tool_name="mcp_runbook",
                        arguments={
                            **base_args,
                            "span_id": "runbook_list",
                            "action": "runbook_list",
                        },
                        label="mcp_runbook:runbook_list",
                    )

                    call_pair(
                        call_id=22,
                        tool_name="mcp_capability",
                        arguments={
                            **base_args,
                            "span_id": "capability_list",
                            "action": "list",
                        },
                        label="mcp_capability:list",
                    )

                    call_pair(
                        call_id=30,
                        tool_name="mcp_state",
                        arguments={
                            **base_args,
                            "span_id": "state_set_a",
                            "action": "set",
                            "scope": "session",
                            "key": "parity.a",
                            "value": 1,
                        },
                        label="mcp_state:set:a",
                    )
                    call_pair(
                        call_id=31,
                        tool_name="mcp_state",
                        arguments={
                            **base_args,
                            "span_id": "state_set_b",
                            "action": "set",
                            "scope": "session",
                            "key": "parity.b",
                            "value": 2,
                        },
                        label="mcp_state:set:b",
                    )
                    call_pair(
                        call_id=32,
                        tool_name="mcp_state",
                        arguments={
                            **base_args,
                            "span_id": "state_list",
                            "action": "list",
                            "scope": "session",
                            "prefix": "parity.",
                            "include_values": True,
                        },
                        label="mcp_state:list:prefix",
                    )

                    call_pair(
                        call_id=40,
                        tool_name="mcp_project",
                        arguments={
                            **base_args,
                            "span_id": "project_list",
                            "action": "project_list",
                        },
                        label="mcp_project:project_list",
                    )
                    call_pair(
                        call_id=41,
                        tool_name="mcp_alias",
                        arguments={
                            **base_args,
                            "span_id": "alias_list",
                            "action": "alias_list",
                        },
                        label="mcp_alias:alias_list",
                    )
                    call_pair(
                        call_id=42,
                        tool_name="mcp_preset",
                        arguments={
                            **base_args,
                            "span_id": "preset_list",
                            "action": "preset_list",
                        },
                        label="mcp_preset:preset_list",
                    )

                    if unsafe_local:
                        call_pair(
                            call_id=50,
                            tool_name="mcp_local",
                            arguments={
                                **base_args,
                                "span_id": "local_exec",
                                "action": "exec",
                                "command": "echo ok",
                            },
                            label="mcp_local:exec",
                        )
            finally:
                rust.terminate()
                ts.terminate()


def main() -> int:
    parser = argparse.ArgumentParser(
        description="Compare Rust vs TS SentryFrogg MCP (tools/list + deterministic tools/call parity suites)."
    )
    parser.add_argument(
        "--ts-path",
        type=str,
        default=None,
        help="Path to TS SentryFrogg repo (default: env SENTRYFROGG_TS_PATH/SF_TS_PATH or well-known path).",
    )
    parser.add_argument(
        "--mode",
        type=str,
        default="both",
        choices=["safe", "unsafe", "both"],
        help="Run parity in safe mode (no local), unsafe mode (local enabled), or both.",
    )
    parser.add_argument(
        "--tier",
        type=str,
        default="full",
        choices=["full", "core"],
        help="Tool tier to compare (full/core).",
    )
    parser.add_argument(
        "--suite",
        type=str,
        default="extended",
        choices=["core", "extended", "full"],
        help="Parity suite: core (help/legend), extended (adds capability/state/project/workspace/runbook + unsafe-local exec smoke), full (reserved).",
    )
    args = parser.parse_args()

    ts_root = Path(args.ts_path).expanduser() if args.ts_path else _default_ts_root()
    if not ts_root or not ts_root.exists():
        sys.stderr.write("ERROR: TS repo not found. Provide --ts-path or set SENTRYFROGG_TS_PATH.\n")
        return 2

    root = _repo_root()
    sys.stdout.write(f"== parity ==\nrepo: {root}\nts:   {ts_root}\n")

    sys.stdout.write("\n$ cargo build\n")
    subprocess.run(["cargo", "build"], cwd=str(root), check=True)

    cases: list[tuple[str, bool]] = []
    if args.mode in {"safe", "both"}:
        cases.append(("safe", False))
    if args.mode in {"unsafe", "both"}:
        cases.append(("unsafe", True))

    for label, unsafe_local in cases:
        sys.stdout.write(f"\n-- case: {label} (tier={args.tier}) --\n")
        _run_case(
            unsafe_local=unsafe_local,
            tool_tier=args.tier,
            suite=args.suite,
            ts_root=ts_root,
        )
        sys.stdout.write("OK\n")

    sys.stdout.write("\nOK: parity\n")
    return 0


if __name__ == "__main__":
    raise SystemExit(main())
